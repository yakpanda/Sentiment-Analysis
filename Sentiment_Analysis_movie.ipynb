{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment Analysis_movie.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPDG0dBSmulZ"
      },
      "source": [
        "#### 네이버 영화 리뷰 데이터에 대한 감정분석"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdNXfIYgqbq6"
      },
      "source": [
        "#### 라이브러리 설치 및 환경 세팅"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWwOfOcPJPiT",
        "outputId": "40547428-5683-4874-c4b1-d71c57fdcf08"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/0c/7d5950fcd80b029be0a8891727ba21e0cd27692c407c51261c3c921f6da3/transformers-4.1.1-py3-none-any.whl (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 13.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 48.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.4)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Collecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 49.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=1bebf20830379cb3abd7f61cfa02e93cb9da998942fc4ccb49156a93140e4b22\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuu01hJFNb7Z",
        "outputId": "d214e18f-9f12-4a21-9802-fdc896814a93"
      },
      "source": [
        "!pip install konlpy"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting konlpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4MB 41.7MB/s \n",
            "\u001b[?25hCollecting JPype1>=0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b7/21/9e2c0dbf9df856e6392a1aec1d18006c60b175aa4e31d351e8278a8a63c0/JPype1-1.2.0-cp36-cp36m-manylinux2010_x86_64.whl (453kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 51.4MB/s \n",
            "\u001b[?25hCollecting tweepy>=3.7.0\n",
            "  Downloading https://files.pythonhosted.org/packages/bb/7c/99d51f80f3b77b107ebae2634108717362c059a41384a1810d13e2429a81/tweepy-3.9.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n",
            "Collecting beautifulsoup4==4.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 11.1MB/s \n",
            "\u001b[?25hCollecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.19.4)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Installing collected packages: JPype1, tweepy, beautifulsoup4, colorama, konlpy\n",
            "  Found existing installation: tweepy 3.6.0\n",
            "    Uninstalling tweepy-3.6.0:\n",
            "      Successfully uninstalled tweepy-3.6.0\n",
            "  Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "Successfully installed JPype1-1.2.0 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2 tweepy-3.9.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C61ATJAdJQRw"
      },
      "source": [
        "import torch\n",
        "\n",
        "from transformers import BertTokenizer\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from konlpy.tag import Okt\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import random\n",
        "import time\n",
        "import datetime\n",
        "from google.colab import files"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XxyG_xky9NI"
      },
      "source": [
        "#### 데이터 로드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwS9f-eGJQY-",
        "outputId": "a084c3e3-45cb-4399-a963-a1a8ce7c40c2"
      },
      "source": [
        "# 네이버 영화리뷰 데이터 다운\n",
        "!git clone https://github.com/e9t/nsmc.git"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'nsmc'...\n",
            "remote: Enumerating objects: 14763, done.\u001b[K\n",
            "remote: Total 14763 (delta 0), reused 0 (delta 0), pack-reused 14763\n",
            "Receiving objects: 100% (14763/14763), 56.19 MiB | 10.25 MiB/s, done.\n",
            "Resolving deltas: 100% (1749/1749), done.\n",
            "Checking out files: 100% (14737/14737), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XI5MurEhUMBd",
        "outputId": "825bc227-e473-4308-d508-3c5e9f079777"
      },
      "source": [
        "# 데이터 df에 저장\n",
        "train = pd.read_csv(\"nsmc/ratings_train.txt\", sep='\\t')\n",
        "test = pd.read_csv(\"nsmc/ratings_test.txt\", sep='\\t')\n",
        "\n",
        "print(train.shape)\n",
        "print(test.shape)\n",
        "\n",
        "#train.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(150000, 3)\n",
            "(50000, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbS5ouktJQwZ",
        "outputId": "571fbe60-8cbf-4cee-ec32-f288cd2c43f6"
      },
      "source": [
        "# 리뷰 문장 확인\n",
        "review_text = train['document']\n",
        "review_text[:5]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                                  아 더빙.. 진짜 짜증나네요 목소리\n",
              "1                    흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나\n",
              "2                                    너무재밓었다그래서보는것을추천한다\n",
              "3                        교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정\n",
              "4    사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...\n",
              "Name: document, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PiF7kGoY2WIn"
      },
      "source": [
        "#### 모델 학습을 위한 전처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19XbTSXrLVQz"
      },
      "source": [
        "# 리뷰 문장에 대해 KoNLPy를 활용하여 단어 토큰화 진행\r\n",
        "okt = Okt()\r\n",
        "\r\n",
        "dm = pd.DataFrame(columns=['document'])\r\n",
        "\r\n",
        "for i in review_text[:5]:\r\n",
        "  a = okt.morphs(str(i), stem = True)\r\n",
        "  a = ' '.join(a)\r\n",
        "  dm = dm.append({'document': a}, ignore_index=True)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9kh05RDWAVB",
        "outputId": "8435f6be-b7c4-439d-a2fd-b7b21204e8e3"
      },
      "source": [
        "# 토큰화 결과 확인\r\n",
        "print(review_text[8])\r\n",
        "print(okt.morphs(str(review_text[8]), stem = True))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "액션이 없는데도 재미 있는 몇안되는 영화\n",
            "['액션', '이', '없다', '재미', '있다', '몇', '안되다', '영화']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBgMTJgTS9HX",
        "outputId": "867e6f8e-99f8-428e-88c4-6958fa98263e"
      },
      "source": [
        "review_text = dm['document']\r\n",
        "review_text[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                                  아 더빙 .. 진짜 짜증나다 목소리\n",
              "1            흠 ... 포스터 보고 초딩 영화 줄 .... 오버 연기 조차 가볍다 않다\n",
              "2                              너 무재 밓었 다그 래서 보다 추천 한 다\n",
              "3                  교도소 이야기 구먼 .. 솔직하다 재미 는 없다 .. 평점 조정\n",
              "4    사이 몬페 그 의 익살스럽다 연기 가 돋보이다 영화 ! 스파이더맨 에서 늙다 보이다...\n",
              "Name: document, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 235
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_3O1ixaLU6z"
      },
      "source": [
        "# KoNLPy 형태소 분석을 활용하여 토큰화 진행\r\n",
        "\r\n",
        "okt = Okt()\r\n",
        "\r\n",
        "cnt=0\r\n",
        "b = []\r\n",
        "for i in review_text:\r\n",
        "  #print(cnt)\r\n",
        "  a = okt.morphs(str(i), stem = True)\r\n",
        "  #a.insert(0, \"[CLS]\")\r\n",
        "  #a.append(\"[SEP]\")\r\n",
        "  b.append(a)\r\n",
        "  #cnt+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvBkDP1m5cjE"
      },
      "source": [
        "#with open('movie_text.txt', 'w') as f:\r\n",
        "    #for i in b:\r\n",
        "        #f.write(\"%s\\n\" % i)\r\n",
        "\r\n",
        "#files.download('movie_text.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u35T0Ah-VNqd",
        "outputId": "d0fb2e96-171d-4c1c-dc71-e857961e3d29"
      },
      "source": [
        "# BERT 형식으로 변환\n",
        "review_text = [\"[CLS] \" + str(text) + \" [SEP]\" for text in review_text]\n",
        "review_text[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS] 아 더빙 .. 진짜 짜증나다 목소리 [SEP]',\n",
              " '[CLS] 흠 ... 포스터 보고 초딩 영화 줄 .... 오버 연기 조차 가볍다 않다 [SEP]',\n",
              " '[CLS] 너 무재 밓었 다그 래서 보다 추천 한 다 [SEP]',\n",
              " '[CLS] 교도소 이야기 구먼 .. 솔직하다 재미 는 없다 .. 평점 조정 [SEP]',\n",
              " '[CLS] 사이 몬페 그 의 익살스럽다 연기 가 돋보이다 영화 ! 스파이더맨 에서 늙다 보이다 하다 커스틴 던스트 가 너무나도 이쁘다 보이다 [SEP]']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 236
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZHEhf3UVNwv",
        "outputId": "aca58734-77a2-406b-f196-dd02709e42cb"
      },
      "source": [
        "# 레이블 추출\n",
        "labels = train['label'].values\n",
        "labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 0, ..., 0, 1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 237
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SuF9yegHVN1k",
        "outputId": "1733a6f0-939f-4756-8d2a-7a030796311c"
      },
      "source": [
        "# 토큰화: 토큰화는 1차적으로 KoNLPy를 이용하여 진행하였고, bert 형식에 맞게 2차 토큰화 진행\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=False)\n",
        "tokenized_texts = [tokenizer.tokenize(text) for text in review_text]\n",
        "\n",
        "print (review_text[0])\n",
        "print (tokenized_texts[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS] 아 더빙 .. 진짜 짜증나다 목소리 [SEP]\n",
            "['[CLS]', '아', '더', '##빙', '.', '.', '진', '##짜', '짜', '##증', '##나다', '목', '##소', '##리', '[SEP]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "jr5N2m9MWYb8",
        "outputId": "edbf137c-b613-4f64-c5af-7ef44fe39bc6"
      },
      "source": [
        "# 입력 토큰의 최대 길이 설정을 위한 확인\r\n",
        "token_lens = []\r\n",
        "for txt in sentences:\r\n",
        "  tokens = tokenizer.encode(txt, max_length=512)\r\n",
        "  token_lens.append(len(tokens))\r\n",
        "\r\n",
        "sns.distplot(token_lens)\r\n",
        "plt.xlim([0, 256]);\r\n",
        "plt.xlabel('Token count');"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.6/dist-packages/seaborn/distributions.py:2551: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rvXiGIWVsw9",
        "outputId": "212c0ca2-e46c-4a96-9ded-f2ecccd2063f"
      },
      "source": [
        "# 입력 토큰의 최대 시퀀스 길이 설정\n",
        "MAX_LEN = 150\n",
        "\n",
        "# 토큰을 숫자 인덱스로 변환\n",
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "\n",
        "# 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "input_ids[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   101,   9519,   9074, 119005,    119,    119,   9708, 119235,\n",
              "         9715, 119230,  89782,   9284,  22333,  12692,    102,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 240
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJEgM5MIVs_1"
      },
      "source": [
        "#print(' Original: ', sentences[0])\n",
        "#print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
        "#print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LuLWaWwk03rH",
        "outputId": "4c9dd1a0-dd24-4a0a-82d4-7c341be7a56f"
      },
      "source": [
        "print(' Original: ', review_text[0])\r\n",
        "print('Tokenized: ', tokenized_texts[0])\r\n",
        "print('Token IDs: ', input_ids[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Original:  [CLS] 아 더빙 .. 진짜 짜증나다 목소리 [SEP]\n",
            "Tokenized:  ['[CLS]', '아', '더', '##빙', '.', '.', '진', '##짜', '짜', '##증', '##나다', '목', '##소', '##리', '[SEP]']\n",
            "Token IDs:  [   101   9519   9074 119005    119    119   9708 119235   9715 119230\n",
            "  89782   9284  22333  12692    102      0      0      0      0      0\n",
            "      0      0      0      0      0      0      0      0      0      0\n",
            "      0      0      0      0      0      0      0      0      0      0\n",
            "      0      0      0      0      0      0      0      0      0      0\n",
            "      0      0      0      0      0      0      0      0      0      0\n",
            "      0      0      0      0      0      0      0      0      0      0\n",
            "      0      0      0      0      0      0      0      0      0      0\n",
            "      0      0      0      0      0      0      0      0      0      0\n",
            "      0      0      0      0      0      0      0      0      0      0\n",
            "      0      0      0      0      0      0      0      0      0      0\n",
            "      0      0      0      0      0      0      0      0      0      0\n",
            "      0      0      0      0      0      0      0      0      0      0\n",
            "      0      0      0      0      0      0      0      0      0      0\n",
            "      0      0      0      0      0      0      0      0      0      0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNSDMcGVVtEd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "373bb451-44ca-4cb3-b336-a33e6bf8ed0e"
      },
      "source": [
        "# 어텐션 마스크 초기화\r\n",
        "attention_masks = []\r\n",
        "\r\n",
        "# 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\r\n",
        "# 패딩 부분은 BERT 모델에서 어텐션을 수행하지 않아 속도 향상\r\n",
        "for seq in input_ids:\r\n",
        "    seq_mask = [float(i>0) for i in seq]\r\n",
        "    attention_masks.append(seq_mask)\r\n",
        "\r\n",
        "print(attention_masks[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LlAm25zVtJX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6158d018-d8e6-4fb4-c074-32128f1ca849"
      },
      "source": [
        "# 훈련셋과 검증셋으로 분리\r\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids,\r\n",
        "                                                                                    labels, \r\n",
        "                                                                                    random_state=22, \r\n",
        "                                                                                    test_size=0.1)\r\n",
        "\r\n",
        "# 어텐션 마스크를 훈련셋과 검증셋으로 분리\r\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, \r\n",
        "                                                       input_ids,\r\n",
        "                                                       random_state=22, \r\n",
        "                                                       test_size=0.1)\r\n",
        "\r\n",
        "# 데이터를 파이토치의 텐서로 변환\r\n",
        "train_inputs = torch.tensor(train_inputs)\r\n",
        "train_labels = torch.tensor(train_labels)\r\n",
        "train_masks = torch.tensor(train_masks)\r\n",
        "validation_inputs = torch.tensor(validation_inputs)\r\n",
        "validation_labels = torch.tensor(validation_labels)\r\n",
        "validation_masks = torch.tensor(validation_masks)\t\t\t\t\r\n",
        "\r\n",
        "print(train_inputs[0])\r\n",
        "print(train_labels[0])\r\n",
        "print(train_masks[0])\r\n",
        "print(validation_inputs[0])\r\n",
        "print(validation_labels[0])\r\n",
        "print(validation_masks[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([   101, 106154,    100,  80564,   9251,  11261,   9143,  11903,   9568,\n",
            "         63243, 106154,  53354,   9654, 118940,   9836,  73352,  80564,   9089,\n",
            "          8985,  12692,  11903,   8996,  43911,   9612,  10407,  14279,   9087,\n",
            "         16985, 118676,  11903,    102,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0])\n",
            "tensor(0)\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0.])\n",
            "tensor([  101,  9559, 11261, 30858, 18227,  9087,  9952, 16439,  9637,  9657,\n",
            "        31401, 30919,   102,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
            "tensor(1)\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0xEK7GhVtOU"
      },
      "source": [
        "# 배치 사이즈\r\n",
        "batch_size = 32\r\n",
        "\r\n",
        "# 파이토치의 DataLoader로 입력, 마스크, 라벨을 묶어 데이터 설정\r\n",
        "# 학습시 배치 사이즈 만큼 데이터를 가져옴\r\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\r\n",
        "train_sampler = RandomSampler(train_data)\r\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\r\n",
        "\r\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\r\n",
        "validation_sampler = SequentialSampler(validation_data)\r\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJoE92Vc92Gb"
      },
      "source": [
        "#### test set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjDP4LDs92RS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5639fed3-0a41-42b2-a604-c98adfd4db2c"
      },
      "source": [
        "# 리뷰 문장 추출\r\n",
        "review_text = test['document']\r\n",
        "review_text[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                                                  굳 ㅋ\n",
              "1                                 GDNTOPCLASSINTHECLUB\n",
              "2               뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아\n",
              "3                     지루하지는 않은데 완전 막장임... 돈주고 보기에는....\n",
              "4    3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??\n",
              "Name: document, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 246
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7-H7oWh78gg",
        "outputId": "da8f66cf-7ae6-4c66-c400-8273bb15938b"
      },
      "source": [
        "len(review_text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 248
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rw3L4LYzUUR0"
      },
      "source": [
        "dm2 = pd.DataFrame(columns=['document'])\r\n",
        "\r\n",
        "for i in review_text:\r\n",
        "  a = okt.morphs(str(i), stem = True)\r\n",
        "  a = ' '.join(a)\r\n",
        "  dm2 = dm2.append({'document': a}, ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "faquHH0ZWHag",
        "outputId": "8c10ffe4-c06d-44b7-946d-3e671bbd1c1b"
      },
      "source": [
        "dm2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>document</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>굳다 ㅋ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>GDNTOPCLASSINTHECLUB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>뭐 야 이 평점 들 은 .... 나쁘다 않다 10 점 짜다 리 는 더 더욱 아니다</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>지루하다 않다 완전 막장 임 ... 돈 주다 보기 에는 ....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3 D 만 아니다 별 다섯 개 주다 .. 왜 3 D 로 나오다 제 심기 를 불편하다...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49995</th>\n",
              "      <td>오랜 만 에 평점 로 기다 하다 ㅋㅋ 킹왕짱 쌈뽕 한 영화 를 만나다 강렬하다 육 쾌함</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49996</th>\n",
              "      <td>의지 박약 들 이나 하다 탈영 은 일단 주인공 김대희 닮다 이등병 찌다 따다 OOOO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49997</th>\n",
              "      <td>그림 도 좋다 완성 도도 높다 ... 보다 내내 불안하다 만들다</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49998</th>\n",
              "      <td>절대 보다 서다 안 되다 영화 .. 재미 도 없다 기분 만 잡 치고 .. 하다 세트...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49999</th>\n",
              "      <td>마무리 는 또 왜 이래</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>50000 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                document\n",
              "0                                                   굳다 ㅋ\n",
              "1                                   GDNTOPCLASSINTHECLUB\n",
              "2          뭐 야 이 평점 들 은 .... 나쁘다 않다 10 점 짜다 리 는 더 더욱 아니다\n",
              "3                    지루하다 않다 완전 막장 임 ... 돈 주다 보기 에는 ....\n",
              "4      3 D 만 아니다 별 다섯 개 주다 .. 왜 3 D 로 나오다 제 심기 를 불편하다...\n",
              "...                                                  ...\n",
              "49995   오랜 만 에 평점 로 기다 하다 ㅋㅋ 킹왕짱 쌈뽕 한 영화 를 만나다 강렬하다 육 쾌함\n",
              "49996    의지 박약 들 이나 하다 탈영 은 일단 주인공 김대희 닮다 이등병 찌다 따다 OOOO\n",
              "49997                그림 도 좋다 완성 도도 높다 ... 보다 내내 불안하다 만들다\n",
              "49998  절대 보다 서다 안 되다 영화 .. 재미 도 없다 기분 만 잡 치고 .. 하다 세트...\n",
              "49999                                       마무리 는 또 왜 이래\n",
              "\n",
              "[50000 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 250
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QTV1mj9WVRp",
        "outputId": "8a905eab-8d9d-480f-9509-f451df3decda"
      },
      "source": [
        "review_text = dm2['document']\r\n",
        "review_text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                                                     굳다 ㅋ\n",
              "1                                     GDNTOPCLASSINTHECLUB\n",
              "2            뭐 야 이 평점 들 은 .... 나쁘다 않다 10 점 짜다 리 는 더 더욱 아니다\n",
              "3                      지루하다 않다 완전 막장 임 ... 돈 주다 보기 에는 ....\n",
              "4        3 D 만 아니다 별 다섯 개 주다 .. 왜 3 D 로 나오다 제 심기 를 불편하다...\n",
              "                               ...                        \n",
              "49995     오랜 만 에 평점 로 기다 하다 ㅋㅋ 킹왕짱 쌈뽕 한 영화 를 만나다 강렬하다 육 쾌함\n",
              "49996      의지 박약 들 이나 하다 탈영 은 일단 주인공 김대희 닮다 이등병 찌다 따다 OOOO\n",
              "49997                  그림 도 좋다 완성 도도 높다 ... 보다 내내 불안하다 만들다\n",
              "49998    절대 보다 서다 안 되다 영화 .. 재미 도 없다 기분 만 잡 치고 .. 하다 세트...\n",
              "49999                                         마무리 는 또 왜 이래\n",
              "Name: document, Length: 50000, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 251
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msTiSSmF76Hz"
      },
      "source": [
        "# KoNLPy 형태소 분석을 활용하여 토큰화 진행\r\n",
        "\r\n",
        "okt = Okt()\r\n",
        "\r\n",
        "cnt=0\r\n",
        "b = []\r\n",
        "for i in review_text:\r\n",
        "  #print(cnt)\r\n",
        "  a = okt.morphs(str(i), stem = True)\r\n",
        "  a.insert(0, \"[CLS]\")\r\n",
        "  a.append(\"[SEP]\")\r\n",
        "  b.append(a)\r\n",
        "  #cnt+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-h68-oX892Wx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f6d5204-01d5-4d56-d213-5137dd8bc329"
      },
      "source": [
        "# BERT의 입력 형식에 맞게 변환\r\n",
        "review_text = [\"[CLS] \" + str(text) + \" [SEP]\" for text in review_text]\r\n",
        "#review_text[:10]\r\n",
        "\r\n",
        "# 라벨 추출\r\n",
        "labels = test['label'].values\r\n",
        "#labels\r\n",
        "\r\n",
        "# BERT의 토크나이저로 문장을 토큰으로 분리\r\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=False)\r\n",
        "tokenized_texts = [tokenizer.tokenize(text) for text in review_text]\r\n",
        "\r\n",
        "#print (sentences[0])\r\n",
        "#print (tokenized_texts[0])\r\n",
        "\r\n",
        "# 입력 토큰의 최대 시퀀스 길이\r\n",
        "MAX_LEN = 150\r\n",
        "\r\n",
        "# 토큰을 숫자 인덱스로 변환\r\n",
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\r\n",
        "\r\n",
        "# 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\r\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\r\n",
        "\r\n",
        "input_ids[0]\r\n",
        "\r\n",
        "# 어텐션 마스크 초기화\r\n",
        "attention_masks = []\r\n",
        "\r\n",
        "# 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\r\n",
        "# 패딩 부분은 BERT 모델에서 어텐션을 수행하지 않아 속도 향상\r\n",
        "for seq in input_ids:\r\n",
        "    seq_mask = [float(i>0) for i in seq]\r\n",
        "    attention_masks.append(seq_mask)\r\n",
        "\r\n",
        "print(attention_masks[0])\r\n",
        "\r\n",
        "\r\n",
        "# 데이터를 파이토치의 텐서로 변환\r\n",
        "test_inputs = torch.tensor(input_ids)\r\n",
        "test_labels = torch.tensor(labels)\r\n",
        "test_masks = torch.tensor(attention_masks)\r\n",
        "\r\n",
        "print(test_inputs[0])\r\n",
        "print(test_labels[0])\r\n",
        "print(test_masks[0])\r\n",
        "\r\n",
        "# 배치 사이즈\r\n",
        "batch_size = 32\r\n",
        "\r\n",
        "# 파이토치의 DataLoader로 입력, 마스크, 라벨을 묶어 데이터 설정\r\n",
        "# 학습시 배치 사이즈 만큼 데이터를 가져옴\r\n",
        "test_data = TensorDataset(test_inputs, test_masks, test_labels)\r\n",
        "test_sampler = RandomSampler(test_data)\r\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "tensor([  101,   101,  8911, 11903,   100,   102,   102,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
            "tensor(1)\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95cJefjd92bf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHRv7jce92gN"
      },
      "source": [
        "#### 모델 생성"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhPtUNMm32rY",
        "outputId": "7ecdc9a6-0767-4bba-d49b-8bda13985f29"
      },
      "source": [
        "# 디바이스 설정\r\n",
        "if torch.cuda.is_available():    \r\n",
        "    device = torch.device(\"cuda\")\r\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\r\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\r\n",
        "else:\r\n",
        "    device = torch.device(\"cpu\")\r\n",
        "    print('No GPU available, using the CPU instead.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYIzd9nB32w5",
        "outputId": "8535077f-1dc9-4096-fdb4-c529e4546be3"
      },
      "source": [
        "# 분류를 위한 BERT 모델 생성\r\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=2)\r\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 256
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8neXEUPF322i"
      },
      "source": [
        "# 옵티마이저 설정\r\n",
        "optimizer = AdamW(model.parameters(),\r\n",
        "                  lr = 2e-5, # 학습률\r\n",
        "                  eps = 1e-8 # 0으로 나누는 것을 방지하기 위한 epsilon 값\r\n",
        "                )\r\n",
        "\r\n",
        "# 에폭수\r\n",
        "epochs = 2\r\n",
        "\r\n",
        "# 총 훈련 스텝 : 배치반복 횟수 * 에폭\r\n",
        "total_steps = len(train_dataloader) * epochs\r\n",
        "\r\n",
        "# 처음에 학습률을 조금씩 변화시키는 스케줄러 생성\r\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \r\n",
        "                                            num_warmup_steps = 0,\r\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6_hmh7p4pXt"
      },
      "source": [
        "# 정확도 계산 함수\r\n",
        "def flat_accuracy(preds, labels):\r\n",
        "    \r\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\r\n",
        "    labels_flat = labels.flatten()\r\n",
        "\r\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2s04oQ9328C"
      },
      "source": [
        "# 시간 표시 함수\r\n",
        "def format_time(elapsed):\r\n",
        "\r\n",
        "    # 반올림\r\n",
        "    elapsed_rounded = int(round((elapsed)))\r\n",
        "    \r\n",
        "    # hh:mm:ss으로 형태 변경\r\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdcjZBqPVtX9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3efff1d0-ae8e-4823-995a-b062967367a5"
      },
      "source": [
        "# 시드 고정\r\n",
        "seed_val = 22\r\n",
        "random.seed(seed_val)\r\n",
        "np.random.seed(seed_val)\r\n",
        "torch.manual_seed(seed_val)\r\n",
        "torch.cuda.manual_seed_all(seed_val)\r\n",
        "\r\n",
        "# 그래디언트 초기화\r\n",
        "model.zero_grad()\r\n",
        "\r\n",
        "# 학습 반복\r\n",
        "for epoch_i in range(0, epochs):\r\n",
        "    \r\n",
        "    # ========================================\r\n",
        "    #               Training\r\n",
        "    # ========================================\r\n",
        "    \r\n",
        "    print(\"\")\r\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\r\n",
        "    print('Training...')\r\n",
        "\r\n",
        "    # 시작 시간 설정\r\n",
        "    t0 = time.time()\r\n",
        "\r\n",
        "    # 로스 초기화\r\n",
        "    total_loss = 0\r\n",
        "\r\n",
        "    # 훈련모드로 변경\r\n",
        "    model.train()\r\n",
        "        \r\n",
        "    # 데이터로더에서 배치만큼 반복하여 가져옴\r\n",
        "    for step, batch in enumerate(train_dataloader):\r\n",
        "        # 경과 정보 표시\r\n",
        "        if step % 500 == 0 and not step == 0:\r\n",
        "            elapsed = format_time(time.time() - t0)\r\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\r\n",
        "\r\n",
        "        # 배치를 GPU에 넣음\r\n",
        "        batch = tuple(t.to(device) for t in batch)\r\n",
        "        \r\n",
        "        # 배치에서 데이터 추출\r\n",
        "        b_input_ids, b_input_mask, b_labels = batch\r\n",
        "\r\n",
        "        # Forward 수행                \r\n",
        "        outputs = model(b_input_ids, \r\n",
        "                        token_type_ids=None, \r\n",
        "                        attention_mask=b_input_mask, \r\n",
        "                        labels=b_labels)\r\n",
        "        \r\n",
        "        # 로스 구함\r\n",
        "        loss = outputs[0]\r\n",
        "\r\n",
        "        # 총 로스 계산\r\n",
        "        total_loss += loss.item()\r\n",
        "\r\n",
        "        # Backward 수행으로 그래디언트 계산\r\n",
        "        loss.backward()\r\n",
        "\r\n",
        "        # 그래디언트 클리핑\r\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\r\n",
        "\r\n",
        "        # 그래디언트를 통해 가중치 파라미터 업데이트\r\n",
        "        optimizer.step()\r\n",
        "\r\n",
        "        # 스케줄러로 학습률 감소\r\n",
        "        scheduler.step()\r\n",
        "\r\n",
        "        # 그래디언트 초기화\r\n",
        "        model.zero_grad()\r\n",
        "\r\n",
        "    # 평균 로스 계산\r\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \r\n",
        "\r\n",
        "    print(\"\")\r\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\r\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\r\n",
        "        \r\n",
        "    # ========================================\r\n",
        "    #               Validation\r\n",
        "    # ========================================\r\n",
        "\r\n",
        "    print(\"\")\r\n",
        "    print(\"Running Validation...\")\r\n",
        "\r\n",
        "    #시작 시간 설정\r\n",
        "    t0 = time.time()\r\n",
        "\r\n",
        "    # 평가모드로 변경\r\n",
        "    model.eval()\r\n",
        "\r\n",
        "    # 변수 초기화\r\n",
        "    eval_loss, eval_accuracy = 0, 0\r\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\r\n",
        "\r\n",
        "    # 데이터로더에서 배치만큼 반복하여 가져옴\r\n",
        "    for batch in validation_dataloader:\r\n",
        "        # 배치를 GPU에 넣음\r\n",
        "        batch = tuple(t.to(device) for t in batch)\r\n",
        "        \r\n",
        "        # 배치에서 데이터 추출\r\n",
        "        b_input_ids, b_input_mask, b_labels = batch\r\n",
        "        \r\n",
        "        # 그래디언트 계산 안함\r\n",
        "        with torch.no_grad():     \r\n",
        "            # Forward 수행\r\n",
        "            outputs = model(b_input_ids, \r\n",
        "                            token_type_ids=None, \r\n",
        "                            attention_mask=b_input_mask)\r\n",
        "        \r\n",
        "        # 로스 구함\r\n",
        "        logits = outputs[0]\r\n",
        "\r\n",
        "        # CPU로 데이터 이동\r\n",
        "        logits = logits.detach().cpu().numpy()\r\n",
        "        label_ids = b_labels.to('cpu').numpy()\r\n",
        "        \r\n",
        "        # 출력 로짓과 라벨을 비교하여 정확도 계산\r\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\r\n",
        "        eval_accuracy += tmp_eval_accuracy\r\n",
        "        nb_eval_steps += 1\r\n",
        "\r\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\r\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\r\n",
        "\r\n",
        "print(\"\")\r\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 2 ========\n",
            "Training...\n",
            "  Batch   500  of  4,219.    Elapsed: 0:06:39.\n",
            "  Batch 1,000  of  4,219.    Elapsed: 0:13:30.\n",
            "  Batch 1,500  of  4,219.    Elapsed: 0:20:21.\n",
            "  Batch 2,000  of  4,219.    Elapsed: 0:27:13.\n",
            "  Batch 2,500  of  4,219.    Elapsed: 0:34:04.\n",
            "  Batch 3,000  of  4,219.    Elapsed: 0:40:56.\n",
            "  Batch 3,500  of  4,219.    Elapsed: 0:47:47.\n",
            "  Batch 4,000  of  4,219.    Elapsed: 0:54:39.\n",
            "\n",
            "  Average training loss: 0.38\n",
            "  Training epcoh took: 0:57:39\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "  Validation took: 0:02:13\n",
            "\n",
            "======== Epoch 2 / 2 ========\n",
            "Training...\n",
            "  Batch   500  of  4,219.    Elapsed: 0:06:51.\n",
            "  Batch 1,000  of  4,219.    Elapsed: 0:13:43.\n",
            "  Batch 1,500  of  4,219.    Elapsed: 0:20:34.\n",
            "  Batch 2,000  of  4,219.    Elapsed: 0:27:26.\n",
            "  Batch 2,500  of  4,219.    Elapsed: 0:34:18.\n",
            "  Batch 3,000  of  4,219.    Elapsed: 0:41:10.\n",
            "  Batch 3,500  of  4,219.    Elapsed: 0:48:02.\n",
            "  Batch 4,000  of  4,219.    Elapsed: 0:54:54.\n",
            "\n",
            "  Average training loss: 0.28\n",
            "  Training epcoh took: 0:57:54\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "  Validation took: 0:02:14\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edq2PV9uxI77"
      },
      "source": [
        "from google.colab import drive\r\n",
        "#drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "B6zGAGwZoGC0",
        "outputId": "65c1b310-3351-4b4d-8488-03c3ddd4d8c4"
      },
      "source": [
        "# 모델 weight save\r\n",
        "torch.save(model.state_dict(), 'checkpoint_2.pth')\r\n",
        "\r\n",
        "# download checkpoint file\r\n",
        "files.download('checkpoint_2.pth')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_36ffe02c-7a53-49d5-9f38-a33b7c4532d7\", \"checkpoint_2.pth\", 711509633)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhgJ6cguweHL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b8dc374-78c3-4985-a171-5d0957a57bbe"
      },
      "source": [
        "# 모델 weight load\r\n",
        "path = F\"/content/drive/MyDrive/Colab Notebooks/NLP/기말_감정분석/checkpoint.pth\"\r\n",
        "model.load_state_dict(torch.load(path))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCRtWMQ7bDCk"
      },
      "source": [
        "#### Prediction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSiz1sIQVN-k",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7CgpmdW5jdGlvbiBfdXBsb2FkRmlsZXMoaW5wdXRJZCwgb3V0cHV0SWQpIHsKICBjb25zdCBzdGVwcyA9IHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCk7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICAvLyBDYWNoZSBzdGVwcyBvbiB0aGUgb3V0cHV0RWxlbWVudCB0byBtYWtlIGl0IGF2YWlsYWJsZSBmb3IgdGhlIG5leHQgY2FsbAogIC8vIHRvIHVwbG9hZEZpbGVzQ29udGludWUgZnJvbSBQeXRob24uCiAgb3V0cHV0RWxlbWVudC5zdGVwcyA9IHN0ZXBzOwoKICByZXR1cm4gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpOwp9CgovLyBUaGlzIGlzIHJvdWdobHkgYW4gYXN5bmMgZ2VuZXJhdG9yIChub3Qgc3VwcG9ydGVkIGluIHRoZSBicm93c2VyIHlldCksCi8vIHdoZXJlIHRoZXJlIGFyZSBtdWx0aXBsZSBhc3luY2hyb25vdXMgc3RlcHMgYW5kIHRoZSBQeXRob24gc2lkZSBpcyBnb2luZwovLyB0byBwb2xsIGZvciBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcC4KLy8gVGhpcyB1c2VzIGEgUHJvbWlzZSB0byBibG9jayB0aGUgcHl0aG9uIHNpZGUgb24gY29tcGxldGlvbiBvZiBlYWNoIHN0ZXAsCi8vIHRoZW4gcGFzc2VzIHRoZSByZXN1bHQgb2YgdGhlIHByZXZpb3VzIHN0ZXAgYXMgdGhlIGlucHV0IHRvIHRoZSBuZXh0IHN0ZXAuCmZ1bmN0aW9uIF91cGxvYWRGaWxlc0NvbnRpbnVlKG91dHB1dElkKSB7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICBjb25zdCBzdGVwcyA9IG91dHB1dEVsZW1lbnQuc3RlcHM7CgogIGNvbnN0IG5leHQgPSBzdGVwcy5uZXh0KG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSk7CiAgcmV0dXJuIFByb21pc2UucmVzb2x2ZShuZXh0LnZhbHVlLnByb21pc2UpLnRoZW4oKHZhbHVlKSA9PiB7CiAgICAvLyBDYWNoZSB0aGUgbGFzdCBwcm9taXNlIHZhbHVlIHRvIG1ha2UgaXQgYXZhaWxhYmxlIHRvIHRoZSBuZXh0CiAgICAvLyBzdGVwIG9mIHRoZSBnZW5lcmF0b3IuCiAgICBvdXRwdXRFbGVtZW50Lmxhc3RQcm9taXNlVmFsdWUgPSB2YWx1ZTsKICAgIHJldHVybiBuZXh0LnZhbHVlLnJlc3BvbnNlOwogIH0pOwp9CgovKioKICogR2VuZXJhdG9yIGZ1bmN0aW9uIHdoaWNoIGlzIGNhbGxlZCBiZXR3ZWVuIGVhY2ggYXN5bmMgc3RlcCBvZiB0aGUgdXBsb2FkCiAqIHByb2Nlc3MuCiAqIEBwYXJhbSB7c3RyaW5nfSBpbnB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIGlucHV0IGZpbGUgcGlja2VyIGVsZW1lbnQuCiAqIEBwYXJhbSB7c3RyaW5nfSBvdXRwdXRJZCBFbGVtZW50IElEIG9mIHRoZSBvdXRwdXQgZGlzcGxheS4KICogQHJldHVybiB7IUl0ZXJhYmxlPCFPYmplY3Q+fSBJdGVyYWJsZSBvZiBuZXh0IHN0ZXBzLgogKi8KZnVuY3Rpb24qIHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IGlucHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKGlucHV0SWQpOwogIGlucHV0RWxlbWVudC5kaXNhYmxlZCA9IGZhbHNlOwoKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIG91dHB1dEVsZW1lbnQuaW5uZXJIVE1MID0gJyc7CgogIGNvbnN0IHBpY2tlZFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgaW5wdXRFbGVtZW50LmFkZEV2ZW50TGlzdGVuZXIoJ2NoYW5nZScsIChlKSA9PiB7CiAgICAgIHJlc29sdmUoZS50YXJnZXQuZmlsZXMpOwogICAgfSk7CiAgfSk7CgogIGNvbnN0IGNhbmNlbCA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2J1dHRvbicpOwogIGlucHV0RWxlbWVudC5wYXJlbnRFbGVtZW50LmFwcGVuZENoaWxkKGNhbmNlbCk7CiAgY2FuY2VsLnRleHRDb250ZW50ID0gJ0NhbmNlbCB1cGxvYWQnOwogIGNvbnN0IGNhbmNlbFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgY2FuY2VsLm9uY2xpY2sgPSAoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9OwogIH0pOwoKICAvLyBXYWl0IGZvciB0aGUgdXNlciB0byBwaWNrIHRoZSBmaWxlcy4KICBjb25zdCBmaWxlcyA9IHlpZWxkIHsKICAgIHByb21pc2U6IFByb21pc2UucmFjZShbcGlja2VkUHJvbWlzZSwgY2FuY2VsUHJvbWlzZV0pLAogICAgcmVzcG9uc2U6IHsKICAgICAgYWN0aW9uOiAnc3RhcnRpbmcnLAogICAgfQogIH07CgogIGNhbmNlbC5yZW1vdmUoKTsKCiAgLy8gRGlzYWJsZSB0aGUgaW5wdXQgZWxlbWVudCBzaW5jZSBmdXJ0aGVyIHBpY2tzIGFyZSBub3QgYWxsb3dlZC4KICBpbnB1dEVsZW1lbnQuZGlzYWJsZWQgPSB0cnVlOwoKICBpZiAoIWZpbGVzKSB7CiAgICByZXR1cm4gewogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgICAgfQogICAgfTsKICB9CgogIGZvciAoY29uc3QgZmlsZSBvZiBmaWxlcykgewogICAgY29uc3QgbGkgPSBkb2N1bWVudC5jcmVhdGVFbGVtZW50KCdsaScpOwogICAgbGkuYXBwZW5kKHNwYW4oZmlsZS5uYW1lLCB7Zm9udFdlaWdodDogJ2JvbGQnfSkpOwogICAgbGkuYXBwZW5kKHNwYW4oCiAgICAgICAgYCgke2ZpbGUudHlwZSB8fCAnbi9hJ30pIC0gJHtmaWxlLnNpemV9IGJ5dGVzLCBgICsKICAgICAgICBgbGFzdCBtb2RpZmllZDogJHsKICAgICAgICAgICAgZmlsZS5sYXN0TW9kaWZpZWREYXRlID8gZmlsZS5sYXN0TW9kaWZpZWREYXRlLnRvTG9jYWxlRGF0ZVN0cmluZygpIDoKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgJ24vYSd9IC0gYCkpOwogICAgY29uc3QgcGVyY2VudCA9IHNwYW4oJzAlIGRvbmUnKTsKICAgIGxpLmFwcGVuZENoaWxkKHBlcmNlbnQpOwoKICAgIG91dHB1dEVsZW1lbnQuYXBwZW5kQ2hpbGQobGkpOwoKICAgIGNvbnN0IGZpbGVEYXRhUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICAgIGNvbnN0IHJlYWRlciA9IG5ldyBGaWxlUmVhZGVyKCk7CiAgICAgIHJlYWRlci5vbmxvYWQgPSAoZSkgPT4gewogICAgICAgIHJlc29sdmUoZS50YXJnZXQucmVzdWx0KTsKICAgICAgfTsKICAgICAgcmVhZGVyLnJlYWRBc0FycmF5QnVmZmVyKGZpbGUpOwogICAgfSk7CiAgICAvLyBXYWl0IGZvciB0aGUgZGF0YSB0byBiZSByZWFkeS4KICAgIGxldCBmaWxlRGF0YSA9IHlpZWxkIHsKICAgICAgcHJvbWlzZTogZmlsZURhdGFQcm9taXNlLAogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbnRpbnVlJywKICAgICAgfQogICAgfTsKCiAgICAvLyBVc2UgYSBjaHVua2VkIHNlbmRpbmcgdG8gYXZvaWQgbWVzc2FnZSBzaXplIGxpbWl0cy4gU2VlIGIvNjIxMTU2NjAuCiAgICBsZXQgcG9zaXRpb24gPSAwOwogICAgd2hpbGUgKHBvc2l0aW9uIDwgZmlsZURhdGEuYnl0ZUxlbmd0aCkgewogICAgICBjb25zdCBsZW5ndGggPSBNYXRoLm1pbihmaWxlRGF0YS5ieXRlTGVuZ3RoIC0gcG9zaXRpb24sIE1BWF9QQVlMT0FEX1NJWkUpOwogICAgICBjb25zdCBjaHVuayA9IG5ldyBVaW50OEFycmF5KGZpbGVEYXRhLCBwb3NpdGlvbiwgbGVuZ3RoKTsKICAgICAgcG9zaXRpb24gKz0gbGVuZ3RoOwoKICAgICAgY29uc3QgYmFzZTY0ID0gYnRvYShTdHJpbmcuZnJvbUNoYXJDb2RlLmFwcGx5KG51bGwsIGNodW5rKSk7CiAgICAgIHlpZWxkIHsKICAgICAgICByZXNwb25zZTogewogICAgICAgICAgYWN0aW9uOiAnYXBwZW5kJywKICAgICAgICAgIGZpbGU6IGZpbGUubmFtZSwKICAgICAgICAgIGRhdGE6IGJhc2U2NCwKICAgICAgICB9LAogICAgICB9OwogICAgICBwZXJjZW50LnRleHRDb250ZW50ID0KICAgICAgICAgIGAke01hdGgucm91bmQoKHBvc2l0aW9uIC8gZmlsZURhdGEuYnl0ZUxlbmd0aCkgKiAxMDApfSUgZG9uZWA7CiAgICB9CiAgfQoKICAvLyBBbGwgZG9uZS4KICB5aWVsZCB7CiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICB9CiAgfTsKfQoKc2NvcGUuZ29vZ2xlID0gc2NvcGUuZ29vZ2xlIHx8IHt9OwpzY29wZS5nb29nbGUuY29sYWIgPSBzY29wZS5nb29nbGUuY29sYWIgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYi5fZmlsZXMgPSB7CiAgX3VwbG9hZEZpbGVzLAogIF91cGxvYWRGaWxlc0NvbnRpbnVlLAp9Owp9KShzZWxmKTsK",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 76
        },
        "outputId": "de3d01b9-2709-48fd-d5d0-bcab01587ea0"
      },
      "source": [
        "## 캐글 데이터\r\n",
        "from google.colab import files\r\n",
        "myfile = files.upload()\r\n",
        "\r\n",
        "#test_kg = pd.read_csv(\"nsmc/ratings_test.txt\", sep='\\t')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b5c5c7ea-a22a-456d-9937-24eaff86df98\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b5c5c7ea-a22a-456d-9937-24eaff86df98\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving ko_data.csv to ko_data.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "9E3YT6bTNYta",
        "outputId": "84727754-f643-4bb9-c539-61302ead5dca"
      },
      "source": [
        "import io\r\n",
        "#pd.read_csv로 csv파일 불러오기\r\n",
        "test_kg = pd.read_csv(io.BytesIO(myfile['ko_data.csv']), encoding='CP949')\r\n",
        "test_kg.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>정말 많이 울었던 영화입니다.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>시간 낭비예요.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>포스터를 저렇게밖에 만들지 못했던 제작자의 소심함에 침을 뱉고 싶다.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>지금 봐도 재미있는 영화!!! 코믹과 감동!!! 그리고 요리!!!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>이걸 영화로 만드는 거야?얼마나 가는지 보자.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id                                Sentence\n",
              "0   0                        정말 많이 울었던 영화입니다.\n",
              "1   1                                시간 낭비예요.\n",
              "2   2  포스터를 저렇게밖에 만들지 못했던 제작자의 소심함에 침을 뱉고 싶다.\n",
              "3   3    지금 봐도 재미있는 영화!!! 코믹과 감동!!! 그리고 요리!!!\n",
              "4   4               이걸 영화로 만드는 거야?얼마나 가는지 보자."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 264
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgoGoniHVOPx"
      },
      "source": [
        "review_text = test_kg.Sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkQpYhkgVRzA",
        "outputId": "ffcc9aa2-cae0-4f2c-815f-0be4e36862a4"
      },
      "source": [
        "review_text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                                         정말 많이 울었던 영화입니다.\n",
              "1                                                 시간 낭비예요.\n",
              "2                   포스터를 저렇게밖에 만들지 못했던 제작자의 소심함에 침을 뱉고 싶다.\n",
              "3                     지금 봐도 재미있는 영화!!! 코믹과 감동!!! 그리고 요리!!!\n",
              "4                                이걸 영화로 만드는 거야?얼마나 가는지 보자.\n",
              "                               ...                        \n",
              "11182    이 영화를 커플에게 추천합니다. 영화관에 가다보면 평생 잊지 못할 추억이 하나 생길...\n",
              "11183                                       심심__ 그냥 한효주 cf\n",
              "11184    공감해서 눈물나는 영화. 안 보신분들이 전부 제가 울었다고 하면 의아해하실텐데 보면...\n",
              "11185                                        오토바이 신은 최고네요.\n",
              "11186                                     개병헌 쓰면 엉망이 된다ㅋㅋㅋ\n",
              "Name: Sentence, Length: 11187, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 278
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAo0e5FS1Qa-"
      },
      "source": [
        "dm2 = pd.DataFrame(columns=['document'])\r\n",
        "\r\n",
        "for i in review_text:\r\n",
        "  a = okt.morphs(str(i), stem = True)\r\n",
        "  a = ' '.join(a)\r\n",
        "  dm2 = dm2.append({'document': a}, ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMOYF5r21InV",
        "outputId": "4933054a-a742-49c0-ccc1-0630acfffddf"
      },
      "source": [
        "review_text = dm2['document']\r\n",
        "review_text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                                         정말 많이 울다 영화 이다 .\n",
              "1                                               시간 낭비 예요 .\n",
              "2             포스터 를 저렇게 밖에 만들다 못 하다 제작자 의 소심하다 침 을 뱉다 싶다 .\n",
              "3                 지금 보다 재미있다 영화 !!! 코믹 과 감동 !!! 그리고 요리 !!!\n",
              "4                             이 걸 영화로 만들다 거야 ? 얼마나 가다 보다 .\n",
              "                               ...                        \n",
              "11182    이 영화 를 커플 에게 추천 하다 . 영화관 에 가다 보다 평생 잊다 못 하다 추억...\n",
              "11183                                      심심 __ 그냥 한효주 cf\n",
              "11184    공감 하다 눈물나다 영화 . 안 보신 분들 이 전부 제 가 울다 하다 의아 하다 보...\n",
              "11185                                     오토바이 신다 최고 네 요 .\n",
              "11186                                  개 병헌 쓰다 엉망 이 되다 ㅋㅋㅋ\n",
              "Name: document, Length: 11187, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 280
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcBzKuewVbgp"
      },
      "source": [
        "#review_text = [str(sentence) for sentence in review_text]\r\n",
        "#sentences = [\"[CLS] \" + str(sentence) + \" [SEP]\" for sentence in sentences]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDeRjRiYGnRF"
      },
      "source": [
        "# 입력 데이터 변환\r\n",
        "def convert_input_data(review_text):\r\n",
        "\r\n",
        "    # BERT의 토크나이저로 문장을 토큰으로 분리\r\n",
        "    tokenized_texts = [tokenizer.tokenize(text) for text in review_text]\r\n",
        "\r\n",
        "    # 입력 토큰의 최대 시퀀스 길이\r\n",
        "    MAX_LEN = 150\r\n",
        "\r\n",
        "    # 토큰을 숫자 인덱스로 변환\r\n",
        "    input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\r\n",
        "    \r\n",
        "    # 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\r\n",
        "    input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\r\n",
        "\r\n",
        "    # 어텐션 마스크 초기화\r\n",
        "    attention_masks = []\r\n",
        "\r\n",
        "    # 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\r\n",
        "    # 패딩 부분은 BERT 모델에서 어텐션을 수행하지 않아 속도 향상\r\n",
        "    for seq in input_ids:\r\n",
        "        seq_mask = [float(i>0) for i in seq]\r\n",
        "        attention_masks.append(seq_mask)\r\n",
        "\r\n",
        "    # 데이터를 파이토치의 텐서로 변환\r\n",
        "    inputs = torch.tensor(input_ids)\r\n",
        "    masks = torch.tensor(attention_masks)\r\n",
        "\r\n",
        "    return inputs, masks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePeYM0gKGrEN"
      },
      "source": [
        "# 문장 테스트\r\n",
        "def test_sentences(review_text):\r\n",
        "\r\n",
        "    # 평가모드로 변경\r\n",
        "    model.eval()\r\n",
        "\r\n",
        "    # 문장을 입력 데이터로 변환\r\n",
        "    inputs, masks = convert_input_data(review_text)\r\n",
        "\r\n",
        "    # 데이터를 GPU에 넣음\r\n",
        "    b_input_ids = inputs.to(device)\r\n",
        "    b_input_mask = masks.to(device)\r\n",
        "            \r\n",
        "    # 그래디언트 계산 안함\r\n",
        "    with torch.no_grad():     \r\n",
        "        # Forward 수행\r\n",
        "        outputs = model(b_input_ids, \r\n",
        "                        token_type_ids=None, \r\n",
        "                        attention_mask=b_input_mask)\r\n",
        "\r\n",
        "    # 로스 구함\r\n",
        "    logits = outputs[0]\r\n",
        "\r\n",
        "    # CPU로 데이터 이동\r\n",
        "    logits = logits.detach().cpu().numpy()\r\n",
        "\r\n",
        "    return logits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJYEOreFWD6D"
      },
      "source": [
        "#logits = test_sentences(review_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqAhw8yVWFmj"
      },
      "source": [
        "#print(logits)\r\n",
        "#print(np.argmax(logits))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQW-nhnnYDjY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6KB_ECNvGnV9",
        "outputId": "b0b0bb5a-42c1-40f2-aa69-956504619160"
      },
      "source": [
        "logits = test_sentences(['연기는 별로지만 재미 하나는 끝내줌!'])\r\n",
        "\r\n",
        "print(logits)\r\n",
        "print(np.argmax(logits))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.5976036  0.6385989]]\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kisfM-NRGnaN",
        "outputId": "87805f7c-af37-456d-bb33-224387515d13"
      },
      "source": [
        "logits = test_sentences(['주연배우가 아깝다. 총체적 난국...'])\r\n",
        "\r\n",
        "print(logits)\r\n",
        "print(np.argmax(logits))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 2.6262083 -3.1040645]]\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXSUvthXXPE1"
      },
      "source": [
        "result = []\r\n",
        "#for i in range(10):\r\n",
        "for i in review_text:\r\n",
        "  #print(review_text[i])\r\n",
        "  logits = test_sentences([i])\r\n",
        "  result.append(np.argmax(logits))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTxklLJXYUbY",
        "outputId": "95edd790-7689-41f1-fd88-7349606d02ae"
      },
      "source": [
        "len(result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11187"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 286
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "ZozfDb5QYxU-",
        "outputId": "784893aa-925a-45fd-c2f8-393eec96248f"
      },
      "source": [
        "result_df = pd.DataFrame(data=result, columns=['Predicted'])\r\n",
        "result_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11182</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11183</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11184</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11185</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11186</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11187 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Predicted\n",
              "0              1\n",
              "1              0\n",
              "2              0\n",
              "3              1\n",
              "4              0\n",
              "...          ...\n",
              "11182          1\n",
              "11183          0\n",
              "11184          1\n",
              "11185          1\n",
              "11186          0\n",
              "\n",
              "[11187 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 287
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "vvb7nWEPYUhn",
        "outputId": "b22eda0a-6bf9-4ecb-e06d-ee1b2bfe9731"
      },
      "source": [
        "result_df.to_csv('sample.csv')\r\n",
        "files.download('sample.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_8411115c-090f-49fa-9be2-edc98b9c5b3f\", \"sample.csv\", 78397)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZ1Wt5QpZ4CY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5UHrvHxdN5O"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfexirZddOAM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIGcJ3EudOGm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzQZwnikdOMk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oxw-u6YoZ31E"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86zJZtpPM7Ei",
        "outputId": "4de1357c-1083-40f6-af54-e39a3bca048d"
      },
      "source": [
        "encoded_review = tokenizer.encode_plus(\r\n",
        "  review_text,\r\n",
        "  max_length=MAX_LEN,\r\n",
        "  add_special_tokens=True,\r\n",
        "  return_token_type_ids=False,\r\n",
        "  pad_to_max_length=True,\r\n",
        "  return_attention_mask=True,\r\n",
        "  return_tensors='pt',\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2179: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMT4zus8lhld",
        "outputId": "15b60233-274d-4b68-ea11-4a91202d21d9"
      },
      "source": [
        "encoded_review = tokenizer.batch_encode_plus(\r\n",
        "    review_text,#.tolist(),\r\n",
        "    max_length = 150,\r\n",
        "    pad_to_max_length=True,\r\n",
        "    truncation=True,\r\n",
        "    return_token_type_ids=False\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2179: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dF2ode-xmSxM"
      },
      "source": [
        "# for test set\r\n",
        "test_seq = torch.tensor(encoded_review['input_ids'])\r\n",
        "test_mask = torch.tensor(encoded_review['attention_mask'])\r\n",
        "#test_y = torch.tensor(test_labels.tolist())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQKu3GfFqTRk",
        "outputId": "33426b86-f7e4-4679-9f65-4bf424204132"
      },
      "source": [
        "# get predictions for test data\r\n",
        "with torch.no_grad():\r\n",
        "  preds = model(test_seq.to(device), test_mask.to(device))\r\n",
        "  #preds = preds.detach().cpu().numpy()\r\n",
        "preds"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SequenceClassifierOutput([('logits', tensor([[-2.2017,  1.8321],\n",
              "                                   [ 0.2802, -0.3147],\n",
              "                                   [-0.1917,  0.0109]], device='cuda:0'))])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aThrgSQQHF39",
        "outputId": "29418641-2254-439a-b762-4cc03994ab0b"
      },
      "source": [
        "review_text ='완전 최고!!'\r\n",
        "\r\n",
        "encoded_review = tokenizer.batch_encode_plus(\r\n",
        "    review_text,#.tolist(),\r\n",
        "    max_length = 150,\r\n",
        "    pad_to_max_length=True,\r\n",
        "    truncation=True,\r\n",
        "    return_token_type_ids=False\r\n",
        ")\r\n",
        "\r\n",
        "preds = model(test_seq.to(device), test_mask.to(device))\r\n",
        "print(preds)\r\n",
        "print(np.argmax(preds))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SequenceClassifierOutput(loss=None, logits=tensor([[-2.2017,  1.8321],\n",
            "        [ 0.2802, -0.3147],\n",
            "        [-0.1917,  0.0109]], device='cuda:0', grad_fn=<AddmmBackward>), hidden_states=None, attentions=None)\n",
            "0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2179: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqxZMdqdHLfN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dCHa36oqTZP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "VERREWL5VDRQ",
        "outputId": "874d96fa-9899-4cbd-8e78-3454bb3c3b5f"
      },
      "source": [
        "input_ids = encoded_review['input_ids'].to(device)\r\n",
        "attention_mask = encoded_review['attention_mask'].to(device)\r\n",
        "output = model(input_ids, attention_mask)\r\n",
        "preds = np.argmax(output, axis = 1)\r\n",
        "print(f'Review text: {review_text}')\r\n",
        "print(f'Sentiment  : {preds}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-15e5ed04d05c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoded_review\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoded_review\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Review text: {review_text}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'to'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sFVlHwrdWa-"
      },
      "source": [
        "input_ids = encoded_review['input_ids'].to(device)\r\n",
        "attention_mask = encoded_review['attention_mask'].to(device)\r\n",
        "output = model(input_ids, attention_mask)\r\n",
        "preds = np.argmax(output, axis = 1)\r\n",
        "print(f'Review text: {review_text}')\r\n",
        "print(f'Sentiment  : {preds}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tt8Uvd51da51",
        "outputId": "8090104a-c970-4d4c-ccec-f6529d44ecf3"
      },
      "source": [
        "preds = np.argmax(preds, axis = -1)\r\n",
        "print(f'Review text: {review_text}')\r\n",
        "print(f'Sentiment  : {preds}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Review text: 짱이다\n",
            "Sentiment  : 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-kY5tUFda-k"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "id": "Ea5Dk7FieT9m",
        "outputId": "19d024cb-1a18-4a21-bb01-e7963b75c9ab"
      },
      "source": [
        "#output = model(input_ids, attention_mask)\r\n",
        "_, prediction = torch.max(preds, dim=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-753fc64b9a4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#output = model(input_ids, attention_mask)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: max() received an invalid combination of arguments - got (numpy.int64, dim=int), but expected one of:\n * (Tensor input)\n * (Tensor input, name dim, bool keepdim, *, tuple of Tensors out)\n * (Tensor input, Tensor other, *, Tensor out)\n * (Tensor input, int dim, bool keepdim, *, tuple of Tensors out)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdC19KQEh7pt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANR9GB_Nh7ed"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGzZXfVAUPmA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ywLGNMBeK4u"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ablbQ5CbeK9s"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2hBazNoeLCV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdve5vLmeLHI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaZaOEIoeLLm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUKc8B3-UPSx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "f02c799f-5f8e-4bb7-86f8-256a41237fc8"
      },
      "source": [
        "import mecab\r\n",
        "    mecab = mecab.MeCab()\r\n",
        "    morph = []\r\n",
        "    sentence = \"담수와 염수가 급작스럽게 섞일 경우 대부분의 수생생물이 폐사하는 원인은?\"\r\n",
        "    for st in sentence.split(\" \"):\r\n",
        "        count = 0\r\n",
        "        for token in mecab.morphs(st):\r\n",
        "            tk = token\r\n",
        "            if count > 0:\r\n",
        "                tk = \"##\" + tk\r\n",
        "                morph.append(tk)\r\n",
        "            else:\r\n",
        "                morph.append(tk)\r\n",
        "                count += 1\r\n",
        "                \r\n",
        "     print(morph)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-470b1b197908>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    mecab = mecab.MeCab()\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ]
    }
  ]
}