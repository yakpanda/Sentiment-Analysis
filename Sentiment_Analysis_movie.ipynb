{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Sentiment Analysis_movie.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c6d85045470b4bb3a60c53f7432780f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d61ab95be56f4c6cab5f3a49fe1b69e8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9e77041545a54bdebb5fcb8018239800",
              "IPY_MODEL_c215cc5401164c9caeb04715e2344c93"
            ]
          }
        },
        "d61ab95be56f4c6cab5f3a49fe1b69e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9e77041545a54bdebb5fcb8018239800": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4fba2787c5874e11938095cbbda0a174",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 625,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 625,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_02cf937130ec4d9e9f61fcb365530348"
          }
        },
        "c215cc5401164c9caeb04715e2344c93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_626057f7c09247c4a151b1b55da152cd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 625/625 [00:12&lt;00:00, 50.7B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0cc140f7a179454b8bd5430d440ca5ed"
          }
        },
        "4fba2787c5874e11938095cbbda0a174": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "02cf937130ec4d9e9f61fcb365530348": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "626057f7c09247c4a151b1b55da152cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0cc140f7a179454b8bd5430d440ca5ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c5a38e3dc75a48b3a499b557672c800f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_652c401785a9486b8c3c3c33053c007b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b46f95913396460fa9074ab2552d691f",
              "IPY_MODEL_0fb30097a08d45b0a7dd9a2f1e190062"
            ]
          }
        },
        "652c401785a9486b8c3c3c33053c007b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b46f95913396460fa9074ab2552d691f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b9ac6a525ca649a5bbaf115ed8f3251c",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 714314041,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 714314041,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c2afb711ae6c483e93b033206f1bc6bd"
          }
        },
        "0fb30097a08d45b0a7dd9a2f1e190062": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9b739940559a4c7097a44bdc25f29e08",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 714M/714M [00:11&lt;00:00, 62.3MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e8124542af8f4d66ac2d26d58e0f05de"
          }
        },
        "b9ac6a525ca649a5bbaf115ed8f3251c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c2afb711ae6c483e93b033206f1bc6bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9b739940559a4c7097a44bdc25f29e08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e8124542af8f4d66ac2d26d58e0f05de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPDG0dBSmulZ"
      },
      "source": [
        "#### 네이버 영화 리뷰 데이터에 대한 감정분석"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdNXfIYgqbq6"
      },
      "source": [
        "#### 라이브러리 설치 및 환경 세팅"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWwOfOcPJPiT",
        "outputId": "af28bbf2-0537-4460-80ea-20bb223f9401"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/0c/7d5950fcd80b029be0a8891727ba21e0cd27692c407c51261c3c921f6da3/transformers-4.1.1-py3-none-any.whl (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 9.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 16.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Collecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 37.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=b60f4135994ceafd5bbc5ba6c9fb2a5dd34d329fd1eb0105b9fddd127c839656\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuu01hJFNb7Z",
        "outputId": "21cd389b-baa9-43a4-eb5d-850a3ea4b86b"
      },
      "source": [
        "!pip install konlpy"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting konlpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4MB 1.2MB/s \n",
            "\u001b[?25hCollecting beautifulsoup4==4.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 12.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Collecting tweepy>=3.7.0\n",
            "  Downloading https://files.pythonhosted.org/packages/bb/7c/99d51f80f3b77b107ebae2634108717362c059a41384a1810d13e2429a81/tweepy-3.9.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.19.4)\n",
            "Collecting JPype1>=0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b7/21/9e2c0dbf9df856e6392a1aec1d18006c60b175aa4e31d351e8278a8a63c0/JPype1-1.2.0-cp36-cp36m-manylinux2010_x86_64.whl (453kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 57.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.12.5)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Installing collected packages: beautifulsoup4, colorama, tweepy, JPype1, konlpy\n",
            "  Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "  Found existing installation: tweepy 3.6.0\n",
            "    Uninstalling tweepy-3.6.0:\n",
            "      Successfully uninstalled tweepy-3.6.0\n",
            "Successfully installed JPype1-1.2.0 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2 tweepy-3.9.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C61ATJAdJQRw"
      },
      "source": [
        "import torch\n",
        "\n",
        "from transformers import BertTokenizer\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from konlpy.tag import Okt\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import random\n",
        "import time\n",
        "import datetime\n",
        "from google.colab import files"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XxyG_xky9NI"
      },
      "source": [
        "#### 데이터 로드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwS9f-eGJQY-",
        "outputId": "c0bcfca2-c24b-4517-b948-dffe2023e874"
      },
      "source": [
        "# 네이버 영화리뷰 데이터 다운\n",
        "!git clone https://github.com/e9t/nsmc.git"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'nsmc'...\n",
            "remote: Enumerating objects: 14763, done.\u001b[K\n",
            "remote: Total 14763 (delta 0), reused 0 (delta 0), pack-reused 14763\u001b[K\n",
            "Receiving objects: 100% (14763/14763), 56.19 MiB | 19.42 MiB/s, done.\n",
            "Resolving deltas: 100% (1749/1749), done.\n",
            "Checking out files: 100% (14737/14737), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XI5MurEhUMBd",
        "outputId": "d2d1d707-0897-4810-b132-cf47588ce9a1"
      },
      "source": [
        "# 데이터 df에 저장\n",
        "train = pd.read_csv(\"nsmc/ratings_train.txt\", sep='\\t')\n",
        "test = pd.read_csv(\"nsmc/ratings_test.txt\", sep='\\t')\n",
        "\n",
        "print(train.shape)\n",
        "print(test.shape)\n",
        "\n",
        "#train.head()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(150000, 3)\n",
            "(50000, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbS5ouktJQwZ",
        "outputId": "252337ad-d3da-47fa-dd4b-6711695bdbb5"
      },
      "source": [
        "# 리뷰 문장 확인\n",
        "review_text = train['document']\n",
        "review_text[:5]"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                                  아 더빙.. 진짜 짜증나네요 목소리\n",
              "1                    흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나\n",
              "2                                    너무재밓었다그래서보는것을추천한다\n",
              "3                        교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정\n",
              "4    사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...\n",
              "Name: document, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PiF7kGoY2WIn"
      },
      "source": [
        "#### 모델 학습을 위한 전처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19XbTSXrLVQz"
      },
      "source": [
        "# 리뷰 문장에 대해 KoNLPy를 활용하여 단어 토큰화 진행\r\n",
        "okt = Okt()\r\n",
        "\r\n",
        "dm = pd.DataFrame(columns=['document'])\r\n",
        "\r\n",
        "for i in review_text:\r\n",
        "  a = okt.morphs(str(i), stem = True)\r\n",
        "  a = ' '.join(a)\r\n",
        "  dm = dm.append({'document': a}, ignore_index=True)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFXoYj6yA9el",
        "outputId": "429f340c-eb8b-4a6f-a03c-b7128fde7221"
      },
      "source": [
        "# 리뷰 문장 확인\r\n",
        "review_text = dm['document']\r\n",
        "review_text[:5]"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                                  아 더빙 .. 진짜 짜증나다 목소리\n",
              "1            흠 ... 포스터 보고 초딩 영화 줄 .... 오버 연기 조차 가볍다 않다\n",
              "2                              너 무재 밓었 다그 래서 보다 추천 한 다\n",
              "3                  교도소 이야기 구먼 .. 솔직하다 재미 는 없다 .. 평점 조정\n",
              "4    사이 몬페 그 의 익살스럽다 연기 가 돋보이다 영화 ! 스파이더맨 에서 늙다 보이다...\n",
              "Name: document, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9kh05RDWAVB"
      },
      "source": [
        "# 토큰화 결과 확인\r\n",
        "#print(review_text[8])\r\n",
        "#print(okt.morphs(str(review_text[8]), stem = True))"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvBkDP1m5cjE"
      },
      "source": [
        "#with open('movie_text.txt', 'w') as f:\r\n",
        "    #for i in b:\r\n",
        "        #f.write(\"%s\\n\" % i)\r\n",
        "\r\n",
        "#files.download('movie_text.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u35T0Ah-VNqd",
        "outputId": "cc49481a-ecda-4ec4-fb74-6aeed7e3df8a"
      },
      "source": [
        "# BERT 형식으로 변환\n",
        "review_text = [\"[CLS] \" + str(text) + \" [SEP]\" for text in review_text]\n",
        "review_text[:5]"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS] 아 더빙 .. 진짜 짜증나다 목소리 [SEP]',\n",
              " '[CLS] 흠 ... 포스터 보고 초딩 영화 줄 .... 오버 연기 조차 가볍다 않다 [SEP]',\n",
              " '[CLS] 너 무재 밓었 다그 래서 보다 추천 한 다 [SEP]',\n",
              " '[CLS] 교도소 이야기 구먼 .. 솔직하다 재미 는 없다 .. 평점 조정 [SEP]',\n",
              " '[CLS] 사이 몬페 그 의 익살스럽다 연기 가 돋보이다 영화 ! 스파이더맨 에서 늙다 보이다 하다 커스틴 던스트 가 너무나도 이쁘다 보이다 [SEP]']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZHEhf3UVNwv",
        "outputId": "95c4b9c8-0c22-4530-e75f-6d0d8163b776"
      },
      "source": [
        "# 레이블 추출\n",
        "labels = train['label'].values\n",
        "labels"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 0, ..., 0, 1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SuF9yegHVN1k",
        "outputId": "bbcde93a-3176-4318-da1f-5ab67bff786f"
      },
      "source": [
        "# 토큰화: 토큰화는 1차적으로 KoNLPy를 이용하여 진행하였고, bert 형식에 맞게 2차 토큰화 진행\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=False)\n",
        "tokenized_texts = [tokenizer.tokenize(text) for text in review_text]\n",
        "\n",
        "print (review_text[0])\n",
        "print (tokenized_texts[0])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS] 아 더빙 .. 진짜 짜증나다 목소리 [SEP]\n",
            "['[CLS]', '아', '더', '##빙', '.', '.', '진', '##짜', '짜', '##증', '##나다', '목', '##소', '##리', '[SEP]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "jr5N2m9MWYb8",
        "outputId": "74c66289-4266-478e-aa33-f9db18d9b772"
      },
      "source": [
        "# 입력 토큰의 최대 길이 설정을 위한 확인\r\n",
        "token_lens = []\r\n",
        "for txt in review_text:\r\n",
        "  tokens = tokenizer.encode(txt, max_length=512)\r\n",
        "  token_lens.append(len(tokens))\r\n",
        "\r\n",
        "sns.distplot(token_lens)\r\n",
        "plt.xlim([0, 256]);\r\n",
        "plt.xlabel('Token count');"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.6/dist-packages/seaborn/distributions.py:2551: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rvXiGIWVsw9"
      },
      "source": [
        "# 최대 길이 설정\n",
        "MAX_LEN = 150\n",
        "\n",
        "# 토큰을 숫자 인덱스로 변환\n",
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "\n",
        "# MAX_LEN 길이에 맞추고 나머지 0으로 패딩\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "# attention mask\n",
        "attention_masks = []\n",
        "\n",
        "# attention mask 패딩 아니면 1, 패딩이면 0\n",
        "for seq in input_ids:\n",
        "    seq_mask = [float(i>0) for i in seq]\n",
        "    attention_masks.append(seq_mask)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LlAm25zVtJX"
      },
      "source": [
        "# train set validation set 분리\r\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids,\r\n",
        "                                                                                    labels, \r\n",
        "                                                                                    random_state=22, \r\n",
        "                                                                                    test_size=0.1)\r\n",
        "\r\n",
        "# attention mask train set validation set 분리\r\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, \r\n",
        "                                                       input_ids,\r\n",
        "                                                       random_state=22, \r\n",
        "                                                       test_size=0.1)\r\n",
        "\r\n",
        "# tensor 변환\r\n",
        "train_inputs = torch.tensor(train_inputs)\r\n",
        "train_labels = torch.tensor(train_labels)\r\n",
        "train_masks = torch.tensor(train_masks)\r\n",
        "validation_inputs = torch.tensor(validation_inputs)\r\n",
        "validation_labels = torch.tensor(validation_labels)\r\n",
        "validation_masks = torch.tensor(validation_masks)\t\t\t\t\r\n",
        "\r\n",
        "# 배치 사이즈\r\n",
        "batch_size = 32\r\n",
        "\r\n",
        "# pytorch DataLoader로 input, mask, label 묶기\r\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\r\n",
        "train_sampler = RandomSampler(train_data)\r\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\r\n",
        "\r\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\r\n",
        "validation_sampler = SequentialSampler(validation_data)\r\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "af2wPcs5CzuT"
      },
      "source": [
        "#### Test data 세팅"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjDP4LDs92RS",
        "outputId": "f105b5c1-e245-41a5-a062-a5da057c89b9"
      },
      "source": [
        "# 리뷰 문장 추출\r\n",
        "review_text = test['document']\r\n",
        "review_text[:5]"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                                                  굳 ㅋ\n",
              "1                                 GDNTOPCLASSINTHECLUB\n",
              "2               뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아\n",
              "3                     지루하지는 않은데 완전 막장임... 돈주고 보기에는....\n",
              "4    3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??\n",
              "Name: document, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7-H7oWh78gg",
        "outputId": "24ccd299-ca90-4858-caa7-985a1e9b2ff1"
      },
      "source": [
        "len(review_text)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rw3L4LYzUUR0"
      },
      "source": [
        "# 리뷰 문장에 대해 KoNLPy를 활용하여 단어 토큰화 진행\r\n",
        "dm2 = pd.DataFrame(columns=['document'])\r\n",
        "\r\n",
        "for i in review_text:\r\n",
        "  a = okt.morphs(str(i), stem = True)\r\n",
        "  a = ' '.join(a)\r\n",
        "  dm2 = dm2.append({'document': a}, ignore_index=True)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "faquHH0ZWHag",
        "outputId": "50816cad-174e-4845-8797-33d6e0f9920f"
      },
      "source": [
        "dm2.head()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>document</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>굳다 ㅋ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>GDNTOPCLASSINTHECLUB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>뭐 야 이 평점 들 은 .... 나쁘다 않다 10 점 짜다 리 는 더 더욱 아니다</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>지루하다 않다 완전 막장 임 ... 돈 주다 보기 에는 ....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3 D 만 아니다 별 다섯 개 주다 .. 왜 3 D 로 나오다 제 심기 를 불편하다...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            document\n",
              "0                                               굳다 ㅋ\n",
              "1                               GDNTOPCLASSINTHECLUB\n",
              "2      뭐 야 이 평점 들 은 .... 나쁘다 않다 10 점 짜다 리 는 더 더욱 아니다\n",
              "3                지루하다 않다 완전 막장 임 ... 돈 주다 보기 에는 ....\n",
              "4  3 D 만 아니다 별 다섯 개 주다 .. 왜 3 D 로 나오다 제 심기 를 불편하다..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QTV1mj9WVRp",
        "outputId": "23b677cc-0c2f-4013-e1f3-9c18151318bd"
      },
      "source": [
        "review_text = dm2['document']\r\n",
        "review_text"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                                                     굳다 ㅋ\n",
              "1                                     GDNTOPCLASSINTHECLUB\n",
              "2            뭐 야 이 평점 들 은 .... 나쁘다 않다 10 점 짜다 리 는 더 더욱 아니다\n",
              "3                      지루하다 않다 완전 막장 임 ... 돈 주다 보기 에는 ....\n",
              "4        3 D 만 아니다 별 다섯 개 주다 .. 왜 3 D 로 나오다 제 심기 를 불편하다...\n",
              "                               ...                        \n",
              "49995     오랜 만 에 평점 로 기다 하다 ㅋㅋ 킹왕짱 쌈뽕 한 영화 를 만나다 강렬하다 육 쾌함\n",
              "49996      의지 박약 들 이나 하다 탈영 은 일단 주인공 김대희 닮다 이등병 찌다 따다 OOOO\n",
              "49997                  그림 도 좋다 완성 도도 높다 ... 보다 내내 불안하다 만들다\n",
              "49998    절대 보다 서다 안 되다 영화 .. 재미 도 없다 기분 만 잡 치고 .. 하다 세트...\n",
              "49999                                         마무리 는 또 왜 이래\n",
              "Name: document, Length: 50000, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-h68-oX892Wx"
      },
      "source": [
        "# BERT의 입력 형식에 맞게 변환\r\n",
        "review_text = [\"[CLS] \" + str(text) + \" [SEP]\" for text in review_text]\r\n",
        "#review_text[:10]\r\n",
        "\r\n",
        "# 라벨 추출\r\n",
        "labels = test['label'].values\r\n",
        "#labels\r\n",
        "\r\n",
        "# BERT의 토크나이저로 문장을 토큰으로 분리\r\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=False)\r\n",
        "tokenized_texts = [tokenizer.tokenize(text) for text in review_text]\r\n",
        "\r\n",
        "#print (sentences[0])\r\n",
        "#print (tokenized_texts[0])\r\n",
        "\r\n",
        "# 입력 토큰의 최대 시퀀스 길이\r\n",
        "MAX_LEN = 150\r\n",
        "\r\n",
        "# 토큰을 숫자 인덱스로 변환\r\n",
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\r\n",
        "\r\n",
        "# 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\r\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\r\n",
        "\r\n",
        "input_ids[0]\r\n",
        "\r\n",
        "# 어텐션 마스크 초기화\r\n",
        "attention_masks = []\r\n",
        "\r\n",
        "# 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\r\n",
        "# 패딩 부분은 BERT 모델에서 어텐션을 수행하지 않아 속도 향상\r\n",
        "for seq in input_ids:\r\n",
        "    seq_mask = [float(i>0) for i in seq]\r\n",
        "    attention_masks.append(seq_mask)\r\n",
        "\r\n",
        "#print(attention_masks[0])\r\n",
        "\r\n",
        "\r\n",
        "# 데이터를 파이토치의 텐서로 변환\r\n",
        "test_inputs = torch.tensor(input_ids)\r\n",
        "test_labels = torch.tensor(labels)\r\n",
        "test_masks = torch.tensor(attention_masks)\r\n",
        "\r\n",
        "#print(test_inputs[0])\r\n",
        "#print(test_labels[0])\r\n",
        "#print(test_masks[0])\r\n",
        "\r\n",
        "# 배치 사이즈\r\n",
        "batch_size = 32\r\n",
        "\r\n",
        "# 파이토치의 DataLoader로 입력, 마스크, 라벨을 묶어 데이터 설정\r\n",
        "# 학습시 배치 사이즈 만큼 데이터를 가져옴\r\n",
        "test_data = TensorDataset(test_inputs, test_masks, test_labels)\r\n",
        "test_sampler = RandomSampler(test_data)\r\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHRv7jce92gN"
      },
      "source": [
        "#### 모델 생성"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhPtUNMm32rY",
        "outputId": "5d6a8d38-a123-4297-b8e7-c7f96a4be66e"
      },
      "source": [
        "# 디바이스 설정\r\n",
        "if torch.cuda.is_available():    \r\n",
        "    device = torch.device(\"cuda\")\r\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\r\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\r\n",
        "else:\r\n",
        "    device = torch.device(\"cpu\")\r\n",
        "    print('No GPU available, using the CPU instead.')"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "c6d85045470b4bb3a60c53f7432780f1",
            "d61ab95be56f4c6cab5f3a49fe1b69e8",
            "9e77041545a54bdebb5fcb8018239800",
            "c215cc5401164c9caeb04715e2344c93",
            "4fba2787c5874e11938095cbbda0a174",
            "02cf937130ec4d9e9f61fcb365530348",
            "626057f7c09247c4a151b1b55da152cd",
            "0cc140f7a179454b8bd5430d440ca5ed",
            "c5a38e3dc75a48b3a499b557672c800f",
            "652c401785a9486b8c3c3c33053c007b",
            "b46f95913396460fa9074ab2552d691f",
            "0fb30097a08d45b0a7dd9a2f1e190062",
            "b9ac6a525ca649a5bbaf115ed8f3251c",
            "c2afb711ae6c483e93b033206f1bc6bd",
            "9b739940559a4c7097a44bdc25f29e08",
            "e8124542af8f4d66ac2d26d58e0f05de"
          ]
        },
        "id": "VYIzd9nB32w5",
        "outputId": "13d7fa13-a4d2-4219-cf7f-cf52be7926a5"
      },
      "source": [
        "# 분류를 위한 BERT 모델 생성\r\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=2)\r\n",
        "model.cuda()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c6d85045470b4bb3a60c53f7432780f1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=625.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c5a38e3dc75a48b3a499b557672c800f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=714314041.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8neXEUPF322i"
      },
      "source": [
        "# 옵티마이저 설정\r\n",
        "optimizer = AdamW(model.parameters(),\r\n",
        "                  lr = 2e-5, # 학습률\r\n",
        "                  eps = 1e-8 # 0으로 나누는 것을 방지하기 위한 epsilon 값\r\n",
        "                )\r\n",
        "\r\n",
        "# 에폭수\r\n",
        "epochs = 2\r\n",
        "\r\n",
        "# 총 훈련 스텝 : 배치반복 횟수 * 에폭\r\n",
        "total_steps = len(train_dataloader) * epochs\r\n",
        "\r\n",
        "# 처음에 학습률을 조금씩 변화시키는 스케줄러 생성\r\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \r\n",
        "                                            num_warmup_steps = 0,\r\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6_hmh7p4pXt"
      },
      "source": [
        "# 정확도 계산 함수\r\n",
        "def flat_accuracy(preds, labels):\r\n",
        "    \r\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\r\n",
        "    labels_flat = labels.flatten()\r\n",
        "\r\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2s04oQ9328C"
      },
      "source": [
        "# 시간 표시 함수\r\n",
        "def format_time(elapsed):\r\n",
        "\r\n",
        "    # 반올림\r\n",
        "    elapsed_rounded = int(round((elapsed)))\r\n",
        "    \r\n",
        "    # hh:mm:ss으로 형태 변경\r\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MdcjZBqPVtX9",
        "outputId": "3efff1d0-ae8e-4823-995a-b062967367a5"
      },
      "source": [
        "# 시드 고정\r\n",
        "seed_val = 22\r\n",
        "random.seed(seed_val)\r\n",
        "np.random.seed(seed_val)\r\n",
        "torch.manual_seed(seed_val)\r\n",
        "torch.cuda.manual_seed_all(seed_val)\r\n",
        "\r\n",
        "# 그래디언트 초기화\r\n",
        "model.zero_grad()\r\n",
        "\r\n",
        "# 학습 반복\r\n",
        "for epoch_i in range(0, epochs):\r\n",
        "    \r\n",
        "    # ========================================\r\n",
        "    #               Training\r\n",
        "    # ========================================\r\n",
        "    \r\n",
        "    print(\"\")\r\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\r\n",
        "    print('Training...')\r\n",
        "\r\n",
        "    # 시작 시간 설정\r\n",
        "    t0 = time.time()\r\n",
        "\r\n",
        "    # 로스 초기화\r\n",
        "    total_loss = 0\r\n",
        "\r\n",
        "    # 훈련모드로 변경\r\n",
        "    model.train()\r\n",
        "        \r\n",
        "    # 데이터로더에서 배치만큼 반복하여 가져옴\r\n",
        "    for step, batch in enumerate(train_dataloader):\r\n",
        "        # 경과 정보 표시\r\n",
        "        if step % 500 == 0 and not step == 0:\r\n",
        "            elapsed = format_time(time.time() - t0)\r\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\r\n",
        "\r\n",
        "        # 배치를 GPU에 넣음\r\n",
        "        batch = tuple(t.to(device) for t in batch)\r\n",
        "        \r\n",
        "        # 배치에서 데이터 추출\r\n",
        "        b_input_ids, b_input_mask, b_labels = batch\r\n",
        "\r\n",
        "        # Forward 수행                \r\n",
        "        outputs = model(b_input_ids, \r\n",
        "                        token_type_ids=None, \r\n",
        "                        attention_mask=b_input_mask, \r\n",
        "                        labels=b_labels)\r\n",
        "        \r\n",
        "        # 로스 구함\r\n",
        "        loss = outputs[0]\r\n",
        "\r\n",
        "        # 총 로스 계산\r\n",
        "        total_loss += loss.item()\r\n",
        "\r\n",
        "        # Backward 수행으로 그래디언트 계산\r\n",
        "        loss.backward()\r\n",
        "\r\n",
        "        # 그래디언트 클리핑\r\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\r\n",
        "\r\n",
        "        # 그래디언트를 통해 가중치 파라미터 업데이트\r\n",
        "        optimizer.step()\r\n",
        "\r\n",
        "        # 스케줄러로 학습률 감소\r\n",
        "        scheduler.step()\r\n",
        "\r\n",
        "        # 그래디언트 초기화\r\n",
        "        model.zero_grad()\r\n",
        "\r\n",
        "    # 평균 로스 계산\r\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \r\n",
        "\r\n",
        "    print(\"\")\r\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\r\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\r\n",
        "        \r\n",
        "    # ========================================\r\n",
        "    #               Validation\r\n",
        "    # ========================================\r\n",
        "\r\n",
        "    print(\"\")\r\n",
        "    print(\"Running Validation...\")\r\n",
        "\r\n",
        "    #시작 시간 설정\r\n",
        "    t0 = time.time()\r\n",
        "\r\n",
        "    # 평가모드로 변경\r\n",
        "    model.eval()\r\n",
        "\r\n",
        "    # 변수 초기화\r\n",
        "    eval_loss, eval_accuracy = 0, 0\r\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\r\n",
        "\r\n",
        "    # 데이터로더에서 배치만큼 반복하여 가져옴\r\n",
        "    for batch in validation_dataloader:\r\n",
        "        # 배치를 GPU에 넣음\r\n",
        "        batch = tuple(t.to(device) for t in batch)\r\n",
        "        \r\n",
        "        # 배치에서 데이터 추출\r\n",
        "        b_input_ids, b_input_mask, b_labels = batch\r\n",
        "        \r\n",
        "        # 그래디언트 계산 안함\r\n",
        "        with torch.no_grad():     \r\n",
        "            # Forward 수행\r\n",
        "            outputs = model(b_input_ids, \r\n",
        "                            token_type_ids=None, \r\n",
        "                            attention_mask=b_input_mask)\r\n",
        "        \r\n",
        "        # 로스 구함\r\n",
        "        logits = outputs[0]\r\n",
        "\r\n",
        "        # CPU로 데이터 이동\r\n",
        "        logits = logits.detach().cpu().numpy()\r\n",
        "        label_ids = b_labels.to('cpu').numpy()\r\n",
        "        \r\n",
        "        # 출력 로짓과 라벨을 비교하여 정확도 계산\r\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\r\n",
        "        eval_accuracy += tmp_eval_accuracy\r\n",
        "        nb_eval_steps += 1\r\n",
        "\r\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\r\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\r\n",
        "\r\n",
        "print(\"\")\r\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 2 ========\n",
            "Training...\n",
            "  Batch   500  of  4,219.    Elapsed: 0:06:39.\n",
            "  Batch 1,000  of  4,219.    Elapsed: 0:13:30.\n",
            "  Batch 1,500  of  4,219.    Elapsed: 0:20:21.\n",
            "  Batch 2,000  of  4,219.    Elapsed: 0:27:13.\n",
            "  Batch 2,500  of  4,219.    Elapsed: 0:34:04.\n",
            "  Batch 3,000  of  4,219.    Elapsed: 0:40:56.\n",
            "  Batch 3,500  of  4,219.    Elapsed: 0:47:47.\n",
            "  Batch 4,000  of  4,219.    Elapsed: 0:54:39.\n",
            "\n",
            "  Average training loss: 0.38\n",
            "  Training epcoh took: 0:57:39\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "  Validation took: 0:02:13\n",
            "\n",
            "======== Epoch 2 / 2 ========\n",
            "Training...\n",
            "  Batch   500  of  4,219.    Elapsed: 0:06:51.\n",
            "  Batch 1,000  of  4,219.    Elapsed: 0:13:43.\n",
            "  Batch 1,500  of  4,219.    Elapsed: 0:20:34.\n",
            "  Batch 2,000  of  4,219.    Elapsed: 0:27:26.\n",
            "  Batch 2,500  of  4,219.    Elapsed: 0:34:18.\n",
            "  Batch 3,000  of  4,219.    Elapsed: 0:41:10.\n",
            "  Batch 3,500  of  4,219.    Elapsed: 0:48:02.\n",
            "  Batch 4,000  of  4,219.    Elapsed: 0:54:54.\n",
            "\n",
            "  Average training loss: 0.28\n",
            "  Training epcoh took: 0:57:54\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "  Validation took: 0:02:14\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edq2PV9uxI77"
      },
      "source": [
        "from google.colab import drive\r\n",
        "#drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "B6zGAGwZoGC0",
        "outputId": "65c1b310-3351-4b4d-8488-03c3ddd4d8c4"
      },
      "source": [
        "# 모델 weight save\r\n",
        "#torch.save(model.state_dict(), 'checkpoint_2.pth')\r\n",
        "\r\n",
        "# download checkpoint file\r\n",
        "#files.download('checkpoint_2.pth')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_36ffe02c-7a53-49d5-9f38-a33b7c4532d7\", \"checkpoint_2.pth\", 711509633)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhgJ6cguweHL",
        "outputId": "c2cb37ab-490e-4a81-9a60-318fa9408264"
      },
      "source": [
        "# 모델 weight load\r\n",
        "#path = F\"/content/drive/MyDrive/Colab Notebooks/NLP/기말_감정분석/checkpoint.pth\"\r\n",
        "#model.load_state_dict(torch.load(path))"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtLEkN4BFj0o"
      },
      "source": [
        "#### 캐글 데이터 예측"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "KwWwBRCcFipD",
        "outputId": "934e9e08-4e4f-40ce-a952-e777ac822526"
      },
      "source": [
        "# 캐글 데이터\r\n",
        "from google.colab import files\r\n",
        "url = 'https://raw.githubusercontent.com/yakpanda/Sentiment-Analysis/main/movie/ko_data.csv'\r\n",
        "kg = pd.read_csv(url, encoding='CP949')\r\n",
        "kg.head()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>정말 많이 울었던 영화입니다.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>시간 낭비예요.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>포스터를 저렇게밖에 만들지 못했던 제작자의 소심함에 침을 뱉고 싶다.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>지금 봐도 재미있는 영화!!! 코믹과 감동!!! 그리고 요리!!!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>이걸 영화로 만드는 거야?얼마나 가는지 보자.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id                                Sentence\n",
              "0   0                        정말 많이 울었던 영화입니다.\n",
              "1   1                                시간 낭비예요.\n",
              "2   2  포스터를 저렇게밖에 만들지 못했던 제작자의 소심함에 침을 뱉고 싶다.\n",
              "3   3    지금 봐도 재미있는 영화!!! 코믹과 감동!!! 그리고 요리!!!\n",
              "4   4               이걸 영화로 만드는 거야?얼마나 가는지 보자."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cM0xZbGYGpi0",
        "outputId": "28f716f8-95cb-4c85-af4c-ac876932316a"
      },
      "source": [
        "review_text = kg['Sentence']\r\n",
        "review_text[:2]"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    정말 많이 울었던 영화입니다.\n",
              "1            시간 낭비예요.\n",
              "Name: Sentence, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAo0e5FS1Qa-"
      },
      "source": [
        "# 리뷰 문장에 대해 KoNLPy를 활용하여 단어 토큰화 진행\r\n",
        "dm3 = pd.DataFrame(columns=['document'])\r\n",
        "\r\n",
        "for i in review_text:\r\n",
        "  a = okt.morphs(str(i), stem = True)\r\n",
        "  a = ' '.join(a)\r\n",
        "  dm3 = dm3.append({'document': a}, ignore_index=True)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMOYF5r21InV",
        "outputId": "85549c27-ab42-4c23-ba7c-6d094c0a607c"
      },
      "source": [
        "review_text = dm3['document']\r\n",
        "review_text[:5]"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                                정말 많이 울다 영화 이다 .\n",
              "1                                      시간 낭비 예요 .\n",
              "2    포스터 를 저렇게 밖에 만들다 못 하다 제작자 의 소심하다 침 을 뱉다 싶다 .\n",
              "3        지금 보다 재미있다 영화 !!! 코믹 과 감동 !!! 그리고 요리 !!!\n",
              "4                    이 걸 영화로 만들다 거야 ? 얼마나 가다 보다 .\n",
              "Name: document, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcBzKuewVbgp"
      },
      "source": [
        "#review_text = [str(sentence) for sentence in review_text]\r\n",
        "#sentences = [\"[CLS] \" + str(sentence) + \" [SEP]\" for sentence in sentences]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDeRjRiYGnRF"
      },
      "source": [
        "# 입력 데이터 변환\r\n",
        "def convert_input_data(review_text):\r\n",
        "\r\n",
        "    # BERT의 토크나이저로 문장을 토큰으로 분리\r\n",
        "    tokenized_texts = [tokenizer.tokenize(text) for text in review_text]\r\n",
        "\r\n",
        "    # 입력 토큰의 최대 시퀀스 길이\r\n",
        "    MAX_LEN = 150\r\n",
        "\r\n",
        "    # 토큰을 숫자 인덱스로 변환\r\n",
        "    input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\r\n",
        "    \r\n",
        "    # 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\r\n",
        "    input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\r\n",
        "\r\n",
        "    # 어텐션 마스크 초기화\r\n",
        "    attention_masks = []\r\n",
        "\r\n",
        "    # 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\r\n",
        "    # 패딩 부분은 BERT 모델에서 어텐션을 수행하지 않아 속도 향상\r\n",
        "    for seq in input_ids:\r\n",
        "        seq_mask = [float(i>0) for i in seq]\r\n",
        "        attention_masks.append(seq_mask)\r\n",
        "\r\n",
        "    # 데이터를 파이토치의 텐서로 변환\r\n",
        "    inputs = torch.tensor(input_ids)\r\n",
        "    masks = torch.tensor(attention_masks)\r\n",
        "\r\n",
        "    return inputs, masks"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePeYM0gKGrEN"
      },
      "source": [
        "# 문장 테스트\r\n",
        "def test_sentences(review_text):\r\n",
        "\r\n",
        "    # 평가모드로 변경\r\n",
        "    model.eval()\r\n",
        "\r\n",
        "    # 문장을 입력 데이터로 변환\r\n",
        "    inputs, masks = convert_input_data(review_text)\r\n",
        "\r\n",
        "    # 데이터를 GPU에 넣음\r\n",
        "    b_input_ids = inputs.to(device)\r\n",
        "    b_input_mask = masks.to(device)\r\n",
        "            \r\n",
        "    # 그래디언트 계산 안함\r\n",
        "    with torch.no_grad():     \r\n",
        "        # Forward 수행\r\n",
        "        outputs = model(b_input_ids, \r\n",
        "                        token_type_ids=None, \r\n",
        "                        attention_mask=b_input_mask)\r\n",
        "\r\n",
        "    # 로스 구함\r\n",
        "    logits = outputs[0]\r\n",
        "\r\n",
        "    # CPU로 데이터 이동\r\n",
        "    logits = logits.detach().cpu().numpy()\r\n",
        "\r\n",
        "    return logits"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXSUvthXXPE1"
      },
      "source": [
        "result = []\r\n",
        "#for i in range(10):\r\n",
        "for i in review_text:\r\n",
        "  #print(review_text[i])\r\n",
        "  logits = test_sentences([i])\r\n",
        "  result.append(np.argmax(logits))"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTxklLJXYUbY",
        "outputId": "56d10e63-2f6d-4896-de70-c089b7153c68"
      },
      "source": [
        "len(result)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11187"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "ZozfDb5QYxU-",
        "outputId": "4670792f-6713-4e58-ad54-567fba7b3685"
      },
      "source": [
        "# 예측 결과\r\n",
        "result_df = pd.DataFrame(data=result, columns=['Predicted'])\r\n",
        "result_df"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11182</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11183</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11184</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11185</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11186</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11187 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Predicted\n",
              "0              1\n",
              "1              0\n",
              "2              0\n",
              "3              1\n",
              "4              0\n",
              "...          ...\n",
              "11182          1\n",
              "11183          0\n",
              "11184          1\n",
              "11185          1\n",
              "11186          0\n",
              "\n",
              "[11187 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "vvb7nWEPYUhn",
        "outputId": "b22eda0a-6bf9-4ecb-e06d-ee1b2bfe9731"
      },
      "source": [
        "result_df.to_csv('sample.csv')\r\n",
        "files.download('sample.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_8411115c-090f-49fa-9be2-edc98b9c5b3f\", \"sample.csv\", 78397)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZ1Wt5QpZ4CY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5UHrvHxdN5O"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}